---
layout: post
title: 贝叶斯决策理论
key: 2018011102
tags: MachineLearning
mathjax: true
modify_date: 2018-01-12 20：42
---

>转载请标明出处：  
>https://seektech.github.io/2018/01/11/贝叶斯决策理论.html [**Miao LI (seektech)**](https://seektech.github.io/2018/01/11/贝叶斯决策理论.html)

贝叶斯决策理论研究了模式类的的概率结构完全知道的情况。

贝叶斯决策理论是解决模式分类问题的一种基本统计途径，假设了决策问题可以用概率的形式来描述并且假设所有有关的概率结构均已知。

条件概率公式：

$$\displaystyle p(x|y) = \frac {p(xy)} {p(y)} $$

贝叶斯公式：

$$\displaystyle p(B|A)=\frac {p(A|B)p(B)}{p(A)}$$

全概率公式：

$$p(A)=\sum \limits_{i=1}^n p(B_i)p(A|B_i)$$

**问题表示：**

类别-$\displaystyle \omega_i, i=1,…,c$

特征矢量-$\mathbf{x}=[x_1,\dots,x_d] \in \mathbb{R}^d$

先验概率-$p(\omega_i)$  $\sum \limits_{i=1}^c p(\omega_i)=1$

概率密度函数(条件概率)-$p(\mathbf{x} \mid \omega_i)$

后验概率-$\displaystyle p(\omega_i \mid \mathbf{x})=\frac {p(\mathbf{x} \mid \omega_i)p(\omega_i)}{p(\mathbf{x})}=\frac {p(\mathbf{x} \mid \omega_i)p(\omega_i)}{\sum \limits_{j=1}^c p(\mathbf{x} \mid \omega_j)p(\omega_j)}$

### [](#header-1)一、最小错误率决策

> 决策过程中自然要寻找使得决策错误率最小的决策行为

**1.** 当只知道先验概率

$$\displaystyle p(error) = \left \lbrace \begin{array} {c} p(\omega_2) \qquad if \ decide \ \omega_1 \\ p(\omega_1) \qquad if \ decide \ \omega_2 \end{array} \right.$$

最小错误率决策，即如果$p(\omega_1) >p(\omega_2)$，决策$\omega_1$，否则$\omega_2$

**2.** 基于后验概率决策

$$\displaystyle p(error) = \left \lbrace \begin{array} {c} p(\omega_2 | \mathbf{x}) \qquad if \ decide \ \omega_1 \\ p(\omega_1| \mathbf{x}) \qquad if \ decide \ \omega_2 \end{array} \right.$$

最小错误率决策，即如果$p(\omega_1|\mathbf{x}) >p(\omega_2|\mathbf{x})$，决策$\omega_1$，否则$\omega_2$

根据后验搞率公式，如果$p(\mathbf{x} \mid \omega_1)p(\omega_1) >p(\mathbf{x}\mid \omega_1)p(\omega_2)$，决策$\omega_1$，否则$\omega_2$


### [](#header-2)二、最小风险决策（贝叶斯决策）

**1.** 最小风险决策

决策代价：将正确的类别$\omega_j$决策为$\alpha_i$时代价(loss)为 $\lambda_{ij}=\lambda(\alpha_i \mid \omega_j)$

条件风险(Conditional Risk)

**2.**带拒识的决策

**3.** 贝叶斯决策用于模式分类

**4.** 离散变量的贝叶斯决策

### [](#header-3)三、判别函数与决策面

### [](#header-4)四、复合模式分类

### [](#header-5)五、概率密度估计方法

如有评论和建议，请移步[CSDN](http://blog.csdn.net/u013413471/article/)  
